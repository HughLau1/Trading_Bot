{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "import statistics\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from keras.models import model_from_json\n",
    "import requests\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_setup(symbol,data_len,seq_len):\n",
    "    \n",
    "    #get dataset, has 6 columns\n",
    "    end = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    start = datetime.datetime.strptime(end, '%Y-%m-%d') - datetime.timedelta(days=(data_len/0.463))\n",
    "    orig_dataset = yf.download(symbol,start,end)\n",
    "    \n",
    "    \n",
    "    print('First 5 rows of dataframe:', orig_dataset.head())\n",
    "    print('Last row of dataframe:', orig_dataset.tail(1))\n",
    "    print('original dataset shape:', orig_dataset.shape)\n",
    "\n",
    "    \n",
    "    #get individual columns\n",
    "    close = orig_dataset['Close'].values\n",
    "    print('Close shape:', close.shape)\n",
    "    open_ = orig_dataset['Open'].values\n",
    "    high = orig_dataset['High'].values\n",
    "    low = orig_dataset['Low'].values\n",
    "    \n",
    "    #Normalize Data\n",
    "    dataset,minmax = normalize_data(orig_dataset)\n",
    "    print('dataset shape:', dataset.shape)\n",
    "\n",
    "    #Get rid of last 2 columns, keep first 4 columns, and put into new array called data\n",
    "    cols = dataset.columns.tolist()\n",
    "    data_seq = list()\n",
    "    for i in range(len(cols)):\n",
    "        if cols[i] < 4:\n",
    "            data_seq.append(dataset[cols[i]].values)\n",
    "            data_seq[i] = data_seq[i].reshape((len(data_seq[i]), 1))\n",
    "    print(len(data_seq))\n",
    "    data = hstack(data_seq)\n",
    "    print('data shape:', data.shape)\n",
    "\n",
    "    #split univariate time series into a trainable datasest, as shown in youtube tutorial\n",
    "    n_steps = seq_len\n",
    "    X, y = split_sequences(data, n_steps)\n",
    "    print('X Shape',X.shape)\n",
    "    print('Y shape', y.shape)\n",
    "    n_features = X.shape[2]\n",
    "    print('n_features:', n_features)\n",
    "    n_seq = len(X)\n",
    "    n_steps = seq_len\n",
    "\n",
    "    #reshape array to fit CNN LSTM\n",
    "    X = X.reshape((n_seq,1, n_steps, n_features))\n",
    "    print('Reshaped X Shape',X.shape)\n",
    "    print('Y shape', y.shape)\n",
    "    true_y = []\n",
    "    for i in range(len(y)):\n",
    "        true_y.append([y[i][0],y[i][1]])\n",
    "        \n",
    "    print('true_y shape:', len(true_y))\n",
    "    \n",
    "    \n",
    "    return X,array(true_y),n_features, minmax, data,  n_steps,close,open_,high,low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "        X, y = list(), list()\n",
    "        for i in range(len(sequences)):\n",
    "            end_ix = i + n_steps\n",
    "            if end_ix > len(sequences)-1:\n",
    "                break\n",
    "            seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataset):\n",
    "        cols = dataset.columns.tolist()\n",
    "        col_name = [0]*len(cols)\n",
    "        for i in range(len(cols)):\n",
    "            col_name[i] = i\n",
    "        dataset.columns = col_name\n",
    "        dtypes = dataset.dtypes.tolist()\n",
    "#         orig_answers = dataset[attr_row_predict].values\n",
    "        minmax = list()\n",
    "        for column in dataset:\n",
    "            dataset = dataset.astype({column: 'float32'})\n",
    "        for i in range(len(cols)):\n",
    "            col_values = dataset[col_name[i]]\n",
    "            value_min = min(col_values)\n",
    "            value_max = max(col_values)\n",
    "            minmax.append([value_min, value_max])\n",
    "        for column in dataset:\n",
    "            values = dataset[column].values\n",
    "            for i in range(len(values)):\n",
    "                values[i] = (values[i] - minmax[column][0]) / (minmax[column][1] - minmax[column][0])\n",
    "            dataset[column] = values\n",
    "        dataset[column] = values\n",
    "        return dataset,minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "First 5 rows of dataframe:                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2020-02-18  185.610001  187.699997  185.500000  187.229996  184.841644   \n",
      "2020-02-19  188.059998  188.179993  186.470001  187.279999  185.395981   \n",
      "2020-02-20  186.949997  187.250000  181.100006  184.419998  182.564758   \n",
      "2020-02-21  183.169998  183.500000  177.250000  178.589996  176.793411   \n",
      "2020-02-24  167.770004  174.550003  163.229996  170.889999  169.170883   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2020-02-18  27792200  \n",
      "2020-02-19  29997500  \n",
      "2020-02-20  36862400  \n",
      "2020-02-21  48572600  \n",
      "2020-02-24  68311100  \n",
      "Last row of dataframe:                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-04-22  260.209991  261.779999  255.639999  257.170013  257.170013   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2021-04-22  25585600  \n",
      "original dataset shape: (298, 6)\n",
      "Close shape: (298,)\n",
      "dataset shape: (298, 6)\n",
      "4\n",
      "data shape: (298, 4)\n",
      "X Shape (294, 4, 4)\n",
      "Y shape (294, 4)\n",
      "n_features: 4\n",
      "Reshaped X Shape (294, 1, 4, 4)\n",
      "Y shape (294, 4)\n",
      "true_y shape: 294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[0.3944806 , 0.38882926, 0.4228252 , 0.41342166],\n",
       "          [0.41436693, 0.39278927, 0.4305666 , 0.41382065],\n",
       "          [0.40535718, 0.3851167 , 0.3877095 , 0.39099908],\n",
       "          [0.37467536, 0.35417867, 0.35698318, 0.34447813]]],\n",
       " \n",
       " \n",
       "        [[[0.41436693, 0.39278927, 0.4305666 , 0.41382065],\n",
       "          [0.40535718, 0.3851167 , 0.3877095 , 0.39099908],\n",
       "          [0.37467536, 0.35417867, 0.35698318, 0.34447813],\n",
       "          [0.24967541, 0.2803399 , 0.2450917 , 0.28303546]]],\n",
       " \n",
       " \n",
       "        [[[0.40535718, 0.3851167 , 0.3877095 , 0.39099908],\n",
       "          [0.37467536, 0.35417867, 0.35698318, 0.34447813],\n",
       "          [0.24967541, 0.2803399 , 0.2450917 , 0.28303546],\n",
       "          [0.30186692, 0.28273237, 0.28036702, 0.26053312]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.9778411 , 0.975662  , 0.9787709 , 0.9589052 ],\n",
       "          [0.98149353, 0.98473716, 0.99928176, 0.9901054 ],\n",
       "          [0.9939936 , 0.9935649 , 0.9982442 , 1.        ],\n",
       "          [0.99983776, 0.99752504, 1.        , 0.98404086]]],\n",
       " \n",
       " \n",
       "        [[[0.98149353, 0.98473716, 0.99928176, 0.9901054 ],\n",
       "          [0.9939936 , 0.9935649 , 0.9982442 , 1.        ],\n",
       "          [0.99983776, 0.99752504, 1.        , 0.98404086],\n",
       "          [0.9806008 , 0.9869649 , 0.9921787 , 0.98021084]]],\n",
       " \n",
       " \n",
       "        [[[0.9939936 , 0.9935649 , 0.9982442 , 1.        ],\n",
       "          [0.99983776, 0.99752504, 1.        , 0.98404086],\n",
       "          [0.9806008 , 0.9869649 , 0.9921787 , 0.98021084],\n",
       "          [0.9896917 , 0.9909248 , 0.99545085, 0.99872327]]]],\n",
       "       dtype=float32),\n",
       " array([[0.24967541, 0.2803399 ],\n",
       "        [0.30186692, 0.28273237],\n",
       "        [0.2654222 , 0.26969713],\n",
       "        [0.2135553 , 0.21829876],\n",
       "        [0.12500007, 0.19090834],\n",
       "        [0.22970782, 0.2668921 ],\n",
       "        [0.2986202 , 0.28405243],\n",
       "        [0.25551957, 0.24857678],\n",
       "        [0.23571436, 0.24997929],\n",
       "        [0.20779227, 0.1859582 ],\n",
       "        [0.11355525, 0.14173743],\n",
       "        [0.17167215, 0.1687979 ],\n",
       "        [0.16331178, 0.1413249 ],\n",
       "        [0.06728903, 0.10642682],\n",
       "        [0.08514615, 0.17605807],\n",
       "        [0.02426952, 0.07243627],\n",
       "        [0.02426952, 0.05717345],\n",
       "        [0.00803576, 0.04479823],\n",
       "        [0.04675333, 0.07903628],\n",
       "        [0.07297082, 0.05387343],\n",
       "        [0.        , 0.        ],\n",
       "        [0.05470784, 0.0744988 ],\n",
       "        [0.09659099, 0.11352195],\n",
       "        [0.0924513 , 0.1327448 ],\n",
       "        [0.11964291, 0.11814201],\n",
       "        [0.12524357, 0.16525039],\n",
       "        [0.181737  , 0.19973594],\n",
       "        [0.12978901, 0.14173743],\n",
       "        [0.12053577, 0.12300956],\n",
       "        [0.14683451, 0.13868491],\n",
       "        [0.18920465, 0.2139262 ],\n",
       "        [0.26444808, 0.24280171],\n",
       "        [0.23262991, 0.21532871],\n",
       "        [0.23823057, 0.22110379],\n",
       "        [0.22191568, 0.20625362],\n",
       "        [0.25965914, 0.27373976],\n",
       "        [0.27751625, 0.2722548 ],\n",
       "        [0.30267864, 0.30286276],\n",
       "        [0.34488642, 0.32530317],\n",
       "        [0.321591  , 0.31499046],\n",
       "        [0.2961851 , 0.27307972],\n",
       "        [0.2790585 , 0.27580228],\n",
       "        [0.30113643, 0.28454742],\n",
       "        [0.28449678, 0.28042236],\n",
       "        [0.32126626, 0.29972765],\n",
       "        [0.31314936, 0.28958002],\n",
       "        [0.2939124 , 0.30616274],\n",
       "        [0.34894487, 0.32860315],\n",
       "        [0.31485397, 0.31408295],\n",
       "        [0.30422089, 0.31705302],\n",
       "        [0.3539773 , 0.35541615],\n",
       "        [0.36582798, 0.35995373],\n",
       "        [0.38279223, 0.36284134],\n",
       "        [0.3893669 , 0.36655387],\n",
       "        [0.374513  , 0.3872617 ],\n",
       "        [0.4041397 , 0.3833841 ],\n",
       "        [0.36964294, 0.35871628],\n",
       "        [0.32897726, 0.33099577],\n",
       "        [0.34131497, 0.38354915],\n",
       "        [0.39561695, 0.37645403],\n",
       "        [0.38977277, 0.37975416],\n",
       "        [0.38798705, 0.37356657],\n",
       "        [0.39277598, 0.3803316 ],\n",
       "        [0.37483773, 0.36209884],\n",
       "        [0.40040588, 0.3789291 ],\n",
       "        [0.3505682 , 0.341721  ],\n",
       "        [0.3549514 , 0.3595412 ],\n",
       "        [0.3711039 , 0.3605313 ],\n",
       "        [0.3695617 , 0.35005358],\n",
       "        [0.38344163, 0.36655387],\n",
       "        [0.3880683 , 0.37430903],\n",
       "        [0.38384748, 0.373484  ],\n",
       "        [0.37021106, 0.38907674],\n",
       "        [0.39715916, 0.39584193],\n",
       "        [0.41387993, 0.41357967],\n",
       "        [0.4392858 , 0.4780959 ],\n",
       "        [0.4555196 , 0.4553254 ],\n",
       "        [0.43449676, 0.42199486],\n",
       "        [0.3861202 , 0.4145698 ],\n",
       "        [0.45357147, 0.45384043],\n",
       "        [0.4709416 , 0.4599456 ],\n",
       "        [0.46258122, 0.4613481 ],\n",
       "        [0.4998377 , 0.4844484 ],\n",
       "        [0.4771104 , 0.49657613],\n",
       "        [0.52824676, 0.5228941 ],\n",
       "        [0.5242696 , 0.51711905],\n",
       "        [0.4934254 , 0.49533865],\n",
       "        [0.50909096, 0.48939854],\n",
       "        [0.47702926, 0.47817832],\n",
       "        [0.49407476, 0.5266066 ],\n",
       "        [0.5367695 , 0.5426945 ],\n",
       "        [0.55738634, 0.55647224],\n",
       "        [0.58295465, 0.5821302 ],\n",
       "        [0.5961039 , 0.6113357 ],\n",
       "        [0.5930196 , 0.59970295],\n",
       "        [0.64383125, 0.62544346],\n",
       "        [0.62183446, 0.6064681 ],\n",
       "        [0.62881494, 0.6206584 ],\n",
       "        [0.56103903, 0.56331986],\n",
       "        [0.5888799 , 0.5837802 ],\n",
       "        [0.5551137 , 0.5373319 ],\n",
       "        [0.547565  , 0.53188676],\n",
       "        [0.55186695, 0.59178287],\n",
       "        [0.6221592 , 0.6053131 ],\n",
       "        [0.5859578 , 0.59178287],\n",
       "        [0.56964296, 0.5803976 ],\n",
       "        [0.5146916 , 0.5139015 ],\n",
       "        [0.52321434, 0.5230591 ],\n",
       "        [0.5405845 , 0.5290817 ],\n",
       "        [0.5315747 , 0.5286692 ],\n",
       "        [0.5193994 , 0.52710176],\n",
       "        [0.5469968 , 0.53238183],\n",
       "        [0.6047891 , 0.6358386 ],\n",
       "        [0.6262987 , 0.61216074],\n",
       "        [0.632224  , 0.61405826],\n",
       "        [0.61144483, 0.6253609 ],\n",
       "        [0.6318183 , 0.6198333 ],\n",
       "        [0.60600656, 0.5883178 ],\n",
       "        [0.5693994 , 0.5534196 ],\n",
       "        [0.5542208 , 0.5751175 ],\n",
       "        [0.58790594, 0.5839453 ],\n",
       "        [0.5823864 , 0.5694249 ],\n",
       "        [0.58920467, 0.5826252 ],\n",
       "        [0.5967533 , 0.5922778 ],\n",
       "        [0.60454553, 0.59013283],\n",
       "        [0.5887175 , 0.61405826],\n",
       "        [0.6237825 , 0.62437093],\n",
       "        [0.63133115, 0.61834836],\n",
       "        [0.61761373, 0.627341  ],\n",
       "        [0.6564124 , 0.67255175],\n",
       "        [0.697078  , 0.747298  ],\n",
       "        [0.7400162 , 0.7430905 ],\n",
       "        [0.73043835, 0.7270852 ],\n",
       "        [0.71834415, 0.7167725 ],\n",
       "        [0.73831177, 0.7614058 ],\n",
       "        [0.74886376, 0.7321178 ],\n",
       "        [0.63384753, 0.6417787 ],\n",
       "        [0.56404227, 0.57305497],\n",
       "        [0.57297087, 0.6127382 ],\n",
       "        [0.6200487 , 0.61191326],\n",
       "        [0.5697241 , 0.56150484],\n",
       "        [0.54569817, 0.56620735],\n",
       "        [0.5796267 , 0.57099247],\n",
       "        [0.5974838 , 0.57817006],\n",
       "        [0.5116884 , 0.52602917],\n",
       "        [0.5340098 , 0.52041906],\n",
       "        [0.4884741 , 0.512664  ],\n",
       "        [0.5523539 , 0.5571323 ],\n",
       "        [0.57540584, 0.5571323 ],\n",
       "        [0.510065  , 0.5362594 ],\n",
       "        [0.5400975 , 0.5648873 ],\n",
       "        [0.59959424, 0.5940104 ],\n",
       "        [0.5871754 , 0.57338506],\n",
       "        [0.574026  , 0.58914274],\n",
       "        [0.62077934, 0.60572565],\n",
       "        [0.5762176 , 0.5809752 ],\n",
       "        [0.56988645, 0.5761901 ],\n",
       "        [0.5828735 , 0.5742925 ],\n",
       "        [0.5685877 , 0.57371503],\n",
       "        [0.59659094, 0.5826252 ],\n",
       "        [0.6024351 , 0.62115335],\n",
       "        [0.6637987 , 0.68715453],\n",
       "        [0.69569814, 0.69829226],\n",
       "        [0.69797087, 0.6901246 ],\n",
       "        [0.6500813 , 0.658279  ],\n",
       "        [0.67483765, 0.6742017 ],\n",
       "        [0.67702925, 0.67428434],\n",
       "        [0.6395293 , 0.633611  ],\n",
       "        [0.617776  , 0.6298985 ],\n",
       "        [0.62435067, 0.6228034 ],\n",
       "        [0.63327926, 0.6246184 ],\n",
       "        [0.6237014 , 0.62511337],\n",
       "        [0.60535717, 0.6113357 ],\n",
       "        [0.573539  , 0.5632373 ],\n",
       "        [0.5443183 , 0.5510271 ],\n",
       "        [0.5396916 , 0.52569914],\n",
       "        [0.5461039 , 0.5338668 ],\n",
       "        [0.54285717, 0.55729717],\n",
       "        [0.62508124, 0.6414488 ],\n",
       "        [0.6901786 , 0.6892995 ],\n",
       "        [0.6919643 , 0.6912796 ],\n",
       "        [0.70965916, 0.7223001 ],\n",
       "        [0.62897736, 0.62643343],\n",
       "        [0.6118507 , 0.63913864],\n",
       "        [0.65097415, 0.6479663 ],\n",
       "        [0.64407474, 0.63402355],\n",
       "        [0.63198054, 0.6366637 ],\n",
       "        [0.6419644 , 0.63616854],\n",
       "        [0.62207794, 0.61546075],\n",
       "        [0.6036527 , 0.59780544],\n",
       "        [0.61030847, 0.59995043],\n",
       "        [0.6001624 , 0.59170026],\n",
       "        [0.5891234 , 0.60787064],\n",
       "        [0.63392866, 0.6164507 ],\n",
       "        [0.6318183 , 0.624536  ],\n",
       "        [0.62573063, 0.61207813],\n",
       "        [0.6290585 , 0.6331986 ],\n",
       "        [0.6320618 , 0.61793584],\n",
       "        [0.6298702 , 0.62544346],\n",
       "        [0.62670463, 0.61719334],\n",
       "        [0.6279221 , 0.6185132 ],\n",
       "        [0.6246754 , 0.63014597],\n",
       "        [0.6343345 , 0.6159557 ],\n",
       "        [0.60681826, 0.59821796],\n",
       "        [0.59285724, 0.60019803],\n",
       "        [0.61761373, 0.62404096],\n",
       "        [0.6344156 , 0.61752325],\n",
       "        [0.63100654, 0.6562165 ],\n",
       "        [0.672565  , 0.6626516 ],\n",
       "        [0.66217536, 0.65275145],\n",
       "        [0.65373385, 0.68830955],\n",
       "        [0.6954546 , 0.7017573 ],\n",
       "        [0.6988637 , 0.68467945],\n",
       "        [0.68514615, 0.685092  ],\n",
       "        [0.7097403 , 0.7050573 ],\n",
       "        [0.7248377 , 0.71454495],\n",
       "        [0.7160714 , 0.7017573 ],\n",
       "        [0.6874189 , 0.6800594 ],\n",
       "        [0.6941559 , 0.6800594 ],\n",
       "        [0.6513799 , 0.6430988 ],\n",
       "        [0.610065  , 0.626351  ],\n",
       "        [0.6252435 , 0.64986384],\n",
       "        [0.6629059 , 0.6600941 ],\n",
       "        [0.66120136, 0.64631635],\n",
       "        [0.6452111 , 0.6313836 ],\n",
       "        [0.62508124, 0.6285784 ],\n",
       "        [0.64042217, 0.63435364],\n",
       "        [0.6210228 , 0.61001563],\n",
       "        [0.6228897 , 0.6303935 ],\n",
       "        [0.65495133, 0.70307726],\n",
       "        [0.7117695 , 0.70728487],\n",
       "        [0.73108774, 0.738388  ],\n",
       "        [0.74764615, 0.73599535],\n",
       "        [0.76988643, 0.77229595],\n",
       "        [0.8197241 , 0.82394195],\n",
       "        [0.80032474, 0.8420922 ],\n",
       "        [0.8034092 , 0.8039766 ],\n",
       "        [0.7958604 , 0.8409372 ],\n",
       "        [0.8465098 , 0.83936965],\n",
       "        [0.8324677 , 0.86230505],\n",
       "        [0.8575488 , 0.8470424 ],\n",
       "        [0.85405844, 0.8473723 ],\n",
       "        [0.861526  , 0.8506723 ],\n",
       "        [0.8511364 , 0.8595825 ],\n",
       "        [0.87654227, 0.8691527 ],\n",
       "        [0.8747566 , 0.86280006],\n",
       "        [0.86785716, 0.86403763],\n",
       "        [0.87678576, 0.87088525],\n",
       "        [0.8466722 , 0.85586995],\n",
       "        [0.8505683 , 0.85273486],\n",
       "        [0.8663962 , 0.8521574 ],\n",
       "        [0.81501627, 0.803234  ],\n",
       "        [0.7574676 , 0.77765864],\n",
       "        [0.7548702 , 0.7807111 ],\n",
       "        [0.7716721 , 0.7756785 ],\n",
       "        [0.76720786, 0.7821136 ],\n",
       "        [0.8026786 , 0.799439  ],\n",
       "        [0.8116883 , 0.7980365 ],\n",
       "        [0.7723215 , 0.76734596],\n",
       "        [0.72832805, 0.7583533 ],\n",
       "        [0.75089294, 0.7647884 ],\n",
       "        [0.76590914, 0.7656134 ],\n",
       "        [0.7781657 , 0.7821962 ],\n",
       "        [0.8116072 , 0.79556143],\n",
       "        [0.79504883, 0.8134642 ],\n",
       "        [0.78733766, 0.7858263 ],\n",
       "        [0.79504883, 0.7806287 ],\n",
       "        [0.80576307, 0.82080686],\n",
       "        [0.8047078 , 0.8083492 ],\n",
       "        [0.77556825, 0.7723785 ],\n",
       "        [0.76306826, 0.75818825],\n",
       "        [0.7569806 , 0.7947363 ],\n",
       "        [0.81558454, 0.82897455],\n",
       "        [0.8185066 , 0.80381155],\n",
       "        [0.7978085 , 0.7950664 ],\n",
       "        [0.7673702 , 0.7931689 ],\n",
       "        [0.8082793 , 0.7939114 ],\n",
       "        [0.7834416 , 0.7695735 ],\n",
       "        [0.7784092 , 0.8128868 ],\n",
       "        [0.823539  , 0.84374225],\n",
       "        [0.8583604 , 0.90248334],\n",
       "        [0.8977274 , 0.89786315],\n",
       "        [0.8993507 , 0.91048586],\n",
       "        [0.9396105 , 0.9369689 ],\n",
       "        [0.9404221 , 0.9522317 ],\n",
       "        [0.95535725, 0.96609205],\n",
       "        [0.9760553 , 0.97863215],\n",
       "        [0.9778411 , 0.975662  ],\n",
       "        [0.98149353, 0.98473716],\n",
       "        [0.9939936 , 0.9935649 ],\n",
       "        [0.99983776, 0.99752504],\n",
       "        [0.9806008 , 0.9869649 ],\n",
       "        [0.9896917 , 0.9909248 ],\n",
       "        [1.        , 1.        ]], dtype=float32),\n",
       " 4,\n",
       " [[137.00999450683594, 260.2099914550781],\n",
       "  [140.57000732421875, 261.7799987792969],\n",
       "  [132.52000427246094, 257.82000732421875],\n",
       "  [135.4199981689453, 260.739990234375],\n",
       "  [134.0576934814453, 260.739990234375],\n",
       "  [10550600.0, 97073600.0]],\n",
       " array([[0.3944806 , 0.38882926, 0.4228252 , 0.41342166],\n",
       "        [0.41436693, 0.39278927, 0.4305666 , 0.41382065],\n",
       "        [0.40535718, 0.3851167 , 0.3877095 , 0.39099908],\n",
       "        ...,\n",
       "        [0.9806008 , 0.9869649 , 0.9921787 , 0.98021084],\n",
       "        [0.9896917 , 0.9909248 , 0.99545085, 0.99872327],\n",
       "        [1.        , 1.        , 0.9826017 , 0.9715131 ]], dtype=float32),\n",
       " 4,\n",
       " array([187.22999573, 187.27999878, 184.41999817, 178.58999634,\n",
       "        170.88999939, 168.07000732, 170.16999817, 158.17999268,\n",
       "        162.00999451, 172.78999329, 164.50999451, 170.55000305,\n",
       "        166.27000427, 161.57000732, 150.61999512, 160.91999817,\n",
       "        153.63000488, 139.05999756, 158.83000183, 135.41999817,\n",
       "        146.57000732, 140.3999939 , 142.71000671, 137.3500061 ,\n",
       "        135.97999573, 148.33999634, 146.91999817, 156.11000061,\n",
       "        149.69999695, 160.22999573, 157.71000671, 152.11000061,\n",
       "        155.25999451, 153.83000183, 165.27000427, 163.49000549,\n",
       "        165.13000488, 165.13999939, 165.50999451, 173.69999695,\n",
       "        171.88000488, 177.03999329, 178.6000061 , 175.05999756,\n",
       "        167.82000732, 173.52000427, 171.41999817, 174.55000305,\n",
       "        174.05000305, 169.80999756, 177.42999268, 179.21000671,\n",
       "        174.57000732, 178.83999634, 180.75999451, 182.53999329,\n",
       "        183.6000061 , 184.67999268, 186.74000549, 182.50999451,\n",
       "        179.75      , 180.52999878, 183.16000366, 184.91000366,\n",
       "        183.63000488, 185.66000366, 183.42999268, 183.50999451,\n",
       "        181.57000732, 181.80999756, 181.3999939 , 183.25      ,\n",
       "        182.83000183, 184.91000366, 185.36000061, 182.91999817,\n",
       "        187.19999695, 188.36000061, 189.80000305, 196.83999634,\n",
       "        186.27000427, 187.74000549, 188.94000244, 193.57000732,\n",
       "        194.24000549, 196.32000732, 195.1499939 , 200.57000732,\n",
       "        201.91000366, 197.83999634, 200.33999634, 196.33000183,\n",
       "        198.44000244, 203.50999451, 204.69999695, 206.25999451,\n",
       "        210.69999695, 208.25      , 212.83000183, 214.32000732,\n",
       "        213.66999817, 207.07000732, 208.3500061 , 208.03999329,\n",
       "        203.91999817, 202.88000488, 211.6000061 , 208.75      ,\n",
       "        211.75      , 202.53999329, 201.30000305, 203.8500061 ,\n",
       "        202.02000427, 204.05999756, 203.8999939 , 205.00999451,\n",
       "        216.53999329, 213.28999329, 212.94000244, 216.3500061 ,\n",
       "        212.47999573, 208.25      , 203.38000488, 209.19000244,\n",
       "        208.69999695, 208.8999939 , 210.27999878, 211.49000549,\n",
       "        209.69999695, 214.58000183, 213.02000427, 213.69000244,\n",
       "        216.47000122, 221.1499939 , 226.58000183, 228.91000366,\n",
       "        225.52999878, 227.27000427, 231.6499939 , 217.30000305,\n",
       "        214.25      , 202.66000366, 211.28999329, 205.36999512,\n",
       "        204.02999878, 205.41000366, 208.77999878, 205.05000305,\n",
       "        202.91000366, 200.38999939, 202.53999329, 207.41999817,\n",
       "        200.58999634, 203.19000244, 207.82000732, 209.44000244,\n",
       "        207.25999451, 210.33000183, 212.46000671, 206.19000244,\n",
       "        210.38000488, 205.91000366, 209.83000183, 210.58000183,\n",
       "        215.80999756, 221.3999939 , 222.86000061, 220.86000061,\n",
       "        219.66000366, 219.66000366, 214.22000122, 214.6499939 ,\n",
       "        214.80000305, 214.88999939, 216.22999573, 210.08000183,\n",
       "        213.25      , 202.67999268, 204.72000122, 202.47000122,\n",
       "        202.33000183, 206.42999268, 216.38999939, 223.28999329,\n",
       "        223.72000122, 218.38999939, 211.00999451, 216.55000305,\n",
       "        215.44000244, 216.50999451, 217.22999573, 214.46000671,\n",
       "        211.08000183, 212.41999817, 210.38999939, 210.11000061,\n",
       "        213.86000061, 213.86999512, 215.22999573, 214.07000732,\n",
       "        216.21000671, 215.36999512, 214.24000549, 214.36000061,\n",
       "        214.28999329, 216.00999451, 211.80000305, 210.52000427,\n",
       "        213.25999451, 214.19999695, 214.13000488, 219.27999878,\n",
       "        219.41999817, 218.58999634, 222.58999634, 223.94000244,\n",
       "        221.02000427, 222.75      , 224.96000671, 224.1499939 ,\n",
       "        221.67999268, 222.41999817, 217.69000244, 217.8999939 ,\n",
       "        212.25      , 218.28999329, 219.61999512, 217.49000549,\n",
       "        214.92999268, 216.33999634, 213.02000427, 212.6499939 ,\n",
       "        216.44000244, 224.33999634, 224.97000122, 225.94999695,\n",
       "        229.52999878, 232.33000183, 232.8999939 , 238.92999268,\n",
       "        231.96000671, 239.6499939 , 239.50999451, 243.        ,\n",
       "        242.00999451, 242.19999695, 242.47000122, 243.77000427,\n",
       "        242.82000732, 244.49000549, 244.99000549, 243.69999695,\n",
       "        244.19999695, 243.78999329, 240.97000122, 234.50999451,\n",
       "        233.27000427, 234.55000305, 228.99000549, 232.38000488,\n",
       "        236.94000244, 233.86999512, 227.55999756, 226.72999573,\n",
       "        231.6000061 , 227.38999939, 233.77999878, 232.41999817,\n",
       "        237.13000488, 235.75      , 234.80999756, 237.71000671,\n",
       "        237.03999329, 230.72000122, 230.3500061 , 235.99000549,\n",
       "        237.58000183, 235.46000671, 232.33999634, 236.47999573,\n",
       "        235.24000549, 231.8500061 , 235.77000427, 242.3500061 ,\n",
       "        249.07000732, 247.86000061, 249.8999939 , 253.25      ,\n",
       "        255.8500061 , 255.91000366, 258.48999023, 255.58999634,\n",
       "        259.5       , 260.73999023, 258.73999023, 258.26000977,\n",
       "        260.57998657, 257.17001343]),\n",
       " array([185.61000061, 188.05999756, 186.94999695, 183.16999817,\n",
       "        167.77000427, 174.19999695, 169.71000671, 163.32000732,\n",
       "        152.41000366, 165.30999756, 173.80000305, 168.49000549,\n",
       "        166.05000305, 162.61000061, 151.        , 158.16000366,\n",
       "        157.13000488, 145.30000305, 147.5       , 140.        ,\n",
       "        140.        , 138.        , 142.77000427, 146.        ,\n",
       "        137.00999451, 143.75      , 148.91000366, 148.3999939 ,\n",
       "        151.75      , 152.44000244, 159.3999939 , 153.        ,\n",
       "        151.86000061, 155.1000061 , 160.32000732, 169.58999634,\n",
       "        165.66999817, 166.36000061, 164.3500061 , 169.        ,\n",
       "        171.19999695, 174.30000305, 179.5       , 176.63000488,\n",
       "        173.5       , 171.38999939, 174.11000061, 172.05999756,\n",
       "        176.58999634, 175.58999634, 173.22000122, 180.        ,\n",
       "        175.80000305, 174.49000549, 180.61999512, 182.08000183,\n",
       "        184.16999817, 184.97999573, 183.1499939 , 186.80000305,\n",
       "        182.55000305, 177.53999329, 179.05999756, 185.75      ,\n",
       "        185.02999878, 184.80999756, 185.3999939 , 183.19000244,\n",
       "        186.33999634, 180.19999695, 180.74000549, 182.72999573,\n",
       "        182.53999329, 184.25      , 184.82000732, 184.30000305,\n",
       "        182.61999512, 185.94000244, 188.        , 191.13000488,\n",
       "        193.13000488, 190.53999329, 184.58000183, 192.88999939,\n",
       "        195.02999878, 194.        , 198.58999634, 195.78999329,\n",
       "        202.08999634, 201.6000061 , 197.80000305, 199.72999573,\n",
       "        195.77999878, 197.88000488, 203.13999939, 205.67999268,\n",
       "        208.83000183, 210.44999695, 210.07000732, 216.33000183,\n",
       "        213.61999512, 214.47999573, 206.13000488, 209.55999756,\n",
       "        205.3999939 , 204.47000122, 205.        , 213.66000366,\n",
       "        209.19999695, 207.19000244, 200.41999817, 201.47000122,\n",
       "        203.61000061, 202.5       , 201.        , 204.3999939 ,\n",
       "        211.52000427, 214.16999817, 214.8999939 , 212.33999634,\n",
       "        214.8500061 , 211.66999817, 207.16000366, 205.28999329,\n",
       "        209.44000244, 208.75999451, 209.6000061 , 210.52999878,\n",
       "        211.49000549, 209.53999329, 213.86000061, 214.78999329,\n",
       "        213.1000061 , 217.88000488, 222.88999939, 228.17999268,\n",
       "        227.        , 225.50999451, 227.97000122, 229.27000427,\n",
       "        215.1000061 , 206.5       , 207.6000061 , 213.3999939 ,\n",
       "        207.19999695, 204.24000549, 208.41999817, 210.61999512,\n",
       "        200.05000305, 202.80000305, 197.19000244, 205.05999756,\n",
       "        207.8999939 , 199.8500061 , 203.55000305, 210.88000488,\n",
       "        209.3500061 , 207.72999573, 213.49000549, 208.        ,\n",
       "        207.22000122, 208.82000732, 207.05999756, 210.50999451,\n",
       "        211.22999573, 218.78999329, 222.72000122, 223.        ,\n",
       "        217.1000061 , 220.1499939 , 220.41999817, 215.80000305,\n",
       "        213.11999512, 213.92999268, 215.02999878, 213.8500061 ,\n",
       "        211.58999634, 207.66999817, 204.07000732, 203.5       ,\n",
       "        204.28999329, 203.88999939, 214.02000427, 222.03999329,\n",
       "        222.25999451, 224.44000244, 214.5       , 212.38999939,\n",
       "        217.21000671, 216.36000061, 214.86999512, 216.1000061 ,\n",
       "        213.6499939 , 211.38000488, 212.19999695, 210.94999695,\n",
       "        209.58999634, 215.11000061, 214.8500061 , 214.1000061 ,\n",
       "        214.50999451, 214.88000488, 214.61000061, 214.22000122,\n",
       "        214.36999512, 213.97000122, 215.16000366, 211.77000427,\n",
       "        210.05000305, 213.1000061 , 215.16999817, 214.75      ,\n",
       "        219.86999512, 218.58999634, 217.55000305, 222.69000244,\n",
       "        223.11000061, 221.41999817, 224.44999695, 226.30999756,\n",
       "        225.22999573, 221.69999695, 222.52999878, 217.25999451,\n",
       "        212.16999817, 214.03999329, 218.67999268, 218.47000122,\n",
       "        216.5       , 214.02000427, 215.91000366, 213.52000427,\n",
       "        213.75      , 217.69999695, 224.69999695, 227.08000183,\n",
       "        229.11999512, 231.86000061, 238.        , 235.61000061,\n",
       "        235.99000549, 235.05999756, 241.30000305, 239.57000732,\n",
       "        242.66000366, 242.22999573, 243.1499939 , 241.86999512,\n",
       "        245.        , 244.77999878, 243.92999268, 245.02999878,\n",
       "        241.32000732, 241.80000305, 243.75      , 237.41999817,\n",
       "        230.33000183, 230.00999451, 232.08000183, 231.52999878,\n",
       "        235.8999939 , 237.00999451, 232.16000366, 226.74000549,\n",
       "        229.52000427, 231.36999512, 232.88000488, 237.        ,\n",
       "        234.96000671, 234.00999451, 234.96000671, 236.27999878,\n",
       "        236.1499939 , 232.55999756, 231.02000427, 230.27000427,\n",
       "        237.49000549, 237.8500061 , 235.30000305, 231.55000305,\n",
       "        236.58999634, 233.52999878, 232.91000366, 238.47000122,\n",
       "        242.75999451, 247.61000061, 247.80999756, 252.77000427,\n",
       "        252.86999512, 254.71000671, 257.26000977, 257.48001099,\n",
       "        257.92999268, 259.47000122, 260.19000244, 257.82000732,\n",
       "        258.94000244, 260.20999146]),\n",
       " array([187.69999695, 188.17999268, 187.25      , 183.5       ,\n",
       "        174.55000305, 174.83999634, 173.25999451, 167.02999878,\n",
       "        163.71000671, 172.91999817, 175.        , 170.69999695,\n",
       "        170.86999512, 163.11000061, 157.75      , 161.02999878,\n",
       "        157.69999695, 153.47000122, 161.91000366, 149.3500061 ,\n",
       "        147.5       , 146.        , 150.1499939 , 147.1000061 ,\n",
       "        140.57000732, 149.6000061 , 154.33000183, 156.66000366,\n",
       "        154.88999939, 160.6000061 , 164.77999878, 157.75      ,\n",
       "        155.47999573, 157.38000488, 166.5       , 170.        ,\n",
       "        166.66999817, 167.36999512, 165.57000732, 173.75      ,\n",
       "        173.57000732, 177.27999878, 180.        , 178.75      ,\n",
       "        173.66999817, 174.        , 175.05999756, 174.55999756,\n",
       "        176.8999939 , 175.66999817, 177.67999268, 180.3999939 ,\n",
       "        178.63999939, 179.        , 183.6499939 , 184.19999695,\n",
       "        184.55000305, 185.        , 187.50999451, 187.03999329,\n",
       "        184.05000305, 180.69000244, 187.05999756, 186.19999695,\n",
       "        186.6000061 , 185.8500061 , 186.66999817, 184.46000671,\n",
       "        186.5       , 181.99000549, 184.1499939 , 184.27000427,\n",
       "        183.        , 185.        , 185.94000244, 185.83999634,\n",
       "        187.72999573, 188.55000305, 190.69999695, 198.52000427,\n",
       "        195.75999451, 191.72000122, 190.82000732, 195.58000183,\n",
       "        196.32000732, 196.49000549, 199.28999329, 200.75999451,\n",
       "        203.94999695, 203.25      , 200.61000061, 199.88999939,\n",
       "        198.52999878, 204.3999939 , 206.3500061 , 208.02000427,\n",
       "        211.13000488, 214.66999817, 213.25999451, 216.38000488,\n",
       "        214.08000183, 215.80000305, 208.8500061 , 211.33000183,\n",
       "        205.69999695, 205.03999329, 212.30000305, 213.94000244,\n",
       "        212.30000305, 210.91999817, 202.86000061, 203.97000122,\n",
       "        204.69999695, 204.6499939 , 204.46000671, 205.1000061 ,\n",
       "        217.63999939, 214.77000427, 215.        , 216.36999512,\n",
       "        215.69999695, 211.88000488, 207.6499939 , 210.27999878,\n",
       "        211.3500061 , 209.58999634, 211.19000244, 212.36000061,\n",
       "        212.1000061 , 215.        , 216.25      , 215.52000427,\n",
       "        216.61000061, 222.08999634, 231.1499939 , 230.63999939,\n",
       "        228.69999695, 227.44999695, 232.86000061, 229.30999756,\n",
       "        218.36000061, 210.02999878, 214.83999634, 214.74000549,\n",
       "        208.63000488, 209.19999695, 209.77999878, 210.6499939 ,\n",
       "        204.33000183, 203.6499939 , 202.71000671, 208.1000061 ,\n",
       "        208.1000061 , 205.57000732, 209.03999329, 212.57000732,\n",
       "        210.07000732, 211.97999573, 213.99000549, 210.99000549,\n",
       "        210.41000366, 210.17999268, 210.11000061, 211.19000244,\n",
       "        215.86000061, 223.86000061, 225.21000671, 224.22000122,\n",
       "        220.36000061, 222.28999329, 222.30000305, 217.36999512,\n",
       "        216.91999817, 216.05999756, 216.27999878, 216.33999634,\n",
       "        214.66999817, 208.83999634, 207.36000061, 204.28999329,\n",
       "        205.27999878, 208.11999512, 218.32000732, 224.11999512,\n",
       "        224.36000061, 228.11999512, 216.5       , 218.03999329,\n",
       "        219.11000061, 217.41999817, 217.74000549, 217.67999268,\n",
       "        215.16999817, 213.02999878, 213.28999329, 212.28999329,\n",
       "        214.25      , 215.28999329, 216.27000427, 214.75999451,\n",
       "        217.32000732, 215.47000122, 216.38000488, 215.38000488,\n",
       "        215.53999329, 216.94999695, 215.22999573, 213.08000183,\n",
       "        213.32000732, 216.21000671, 215.41999817, 220.11000061,\n",
       "        220.88999939, 219.69000244, 224.        , 225.63000488,\n",
       "        223.55999756, 223.61000061, 226.02999878, 227.17999268,\n",
       "        225.63000488, 223.        , 223.        , 218.52000427,\n",
       "        216.49000549, 219.33999634, 220.58000183, 218.91000366,\n",
       "        217.1000061 , 216.75999451, 217.46000671, 214.50999451,\n",
       "        216.97999573, 225.78999329, 226.30000305, 230.07000732,\n",
       "        229.77999878, 234.17999268, 240.44000244, 242.63999939,\n",
       "        238.02000427, 242.5       , 242.30999756, 245.08999634,\n",
       "        243.24000549, 243.27999878, 243.67999268, 244.75999451,\n",
       "        245.91999817, 245.1499939 , 245.30000305, 246.13000488,\n",
       "        244.30999756, 243.92999268, 243.86000061, 237.92999268,\n",
       "        234.83000183, 235.19999695, 234.58999634, 235.36999512,\n",
       "        237.47000122, 237.30000305, 233.58000183, 232.49000549,\n",
       "        233.27000427, 233.36999512, 235.38000488, 237.        ,\n",
       "        239.16999817, 235.82000732, 235.19000244, 240.05999756,\n",
       "        238.55000305, 234.19000244, 232.47000122, 236.8999939 ,\n",
       "        241.05000305, 238.        , 236.94000244, 236.71000671,\n",
       "        236.80000305, 233.8500061 , 239.1000061 , 242.83999634,\n",
       "        249.96000671, 249.3999939 , 250.92999268, 254.13999939,\n",
       "        255.99000549, 257.67001343, 259.19000244, 258.82998657,\n",
       "        259.92999268, 261.        , 261.48001099, 260.20001221,\n",
       "        260.67999268, 261.77999878]),\n",
       " array([185.5       , 186.47000122, 181.1000061 , 177.25      ,\n",
       "        163.22999573, 167.6499939 , 168.21000671, 157.97999573,\n",
       "        152.        , 162.30999756, 162.25999451, 165.61999512,\n",
       "        165.69000244, 156.        , 150.        , 152.58000183,\n",
       "        151.1499939 , 138.58000183, 140.72999573, 135.        ,\n",
       "        135.        , 135.02000427, 139.        , 135.86000061,\n",
       "        132.52000427, 141.27000427, 144.44000244, 148.36999512,\n",
       "        149.19999695, 150.00999451, 156.55999756, 150.82000732,\n",
       "        150.36000061, 152.19000244, 157.58000183, 163.25999451,\n",
       "        163.5       , 163.33000183, 162.30000305, 168.        ,\n",
       "        169.24000549, 172.8999939 , 175.86999512, 174.99000549,\n",
       "        166.11000061, 170.82000732, 170.91000366, 170.71000671,\n",
       "        173.30000305, 169.38999939, 171.88000488, 176.22999573,\n",
       "        174.00999451, 173.80000305, 179.8999939 , 181.63000488,\n",
       "        182.58000183, 183.36000061, 182.8500061 , 182.30000305,\n",
       "        176.53999329, 175.67999268, 177.        , 183.96000671,\n",
       "        183.49000549, 183.94000244, 183.28999329, 182.53999329,\n",
       "        181.1000061 , 176.6000061 , 180.38000488, 180.41000366,\n",
       "        181.46000671, 181.3500061 , 183.58000183, 182.30000305,\n",
       "        182.00999451, 184.44000244, 187.25999451, 191.00999451,\n",
       "        186.07000732, 185.17999268, 184.00999451, 191.46000671,\n",
       "        193.69000244, 194.        , 194.36999512, 195.22999573,\n",
       "        201.42999268, 196.55999756, 195.47000122, 194.88000488,\n",
       "        193.55000305, 197.74000549, 201.77000427, 205.        ,\n",
       "        208.08999634, 207.99000549, 208.69000244, 211.47000122,\n",
       "        211.08000183, 206.5       , 202.02999878, 205.02999878,\n",
       "        202.30999756, 201.38999939, 203.00999451, 208.02999878,\n",
       "        208.38999939, 202.1499939 , 197.50999451, 200.86000061,\n",
       "        201.74000549, 202.00999451, 199.57000732, 199.00999451,\n",
       "        210.44000244, 210.30999756, 211.57000732, 211.55000305,\n",
       "        210.92999268, 206.3500061 , 203.13999939, 204.75      ,\n",
       "        208.1499939 , 207.50999451, 208.91999817, 209.21000671,\n",
       "        209.25      , 208.91000366, 212.8500061 , 212.42999268,\n",
       "        213.1000061 , 217.36000061, 219.3999939 , 226.58000183,\n",
       "        224.30999756, 224.42999268, 227.3500061 , 214.96000671,\n",
       "        205.19000244, 202.19999695, 206.69999695, 204.11000061,\n",
       "        201.24000549, 204.02999878, 206.92999268, 204.63999939,\n",
       "        199.96000671, 196.25      , 196.38000488, 202.08000183,\n",
       "        200.02999878, 199.19999695, 202.53999329, 208.05999756,\n",
       "        206.80999756, 206.53999329, 211.32000732, 205.53999329,\n",
       "        206.97999573, 204.82000732, 206.72000122, 208.32000732,\n",
       "        211.22999573, 216.80999756, 220.42999268, 219.13000488,\n",
       "        216.00999451, 219.32000732, 213.72000122, 213.08999634,\n",
       "        213.11999512, 211.69999695, 213.16000366, 208.1000061 ,\n",
       "        210.33000183, 202.1000061 , 203.36999512, 199.61999512,\n",
       "        200.11999512, 203.11999512, 212.41999817, 221.1499939 ,\n",
       "        218.02999878, 217.88000488, 209.72000122, 212.19999695,\n",
       "        214.46000671, 214.16000366, 214.52000427, 214.08000183,\n",
       "        210.92999268, 209.92999268, 210.        , 208.16000366,\n",
       "        208.86000061, 212.46000671, 214.03999329, 210.83999634,\n",
       "        213.3500061 , 212.80000305, 213.6499939 , 213.17999268,\n",
       "        212.99000549, 212.88999939, 211.21000671, 210.36000061,\n",
       "        209.11000061, 212.88000488, 212.24000549, 214.72000122,\n",
       "        217.91999817, 216.02000427, 217.27999878, 221.8500061 ,\n",
       "        220.80000305, 221.19999695, 223.02000427, 223.58000183,\n",
       "        221.47000122, 219.67999268, 214.80999756, 215.69999695,\n",
       "        211.94000244, 213.71000671, 217.02999878, 216.72999573,\n",
       "        213.32000732, 213.92999268, 212.74000549, 212.02999878,\n",
       "        212.63000488, 217.28999329, 222.41999817, 225.80000305,\n",
       "        224.22000122, 230.08000183, 230.13999939, 235.08999634,\n",
       "        231.3500061 , 232.42999268, 238.69000244, 239.25999451,\n",
       "        240.36999512, 240.41999817, 240.80999756, 241.38000488,\n",
       "        240.88999939, 242.1499939 , 242.72999573, 242.91999817,\n",
       "        240.94000244, 240.86000061, 240.17999268, 232.3999939 ,\n",
       "        228.72999573, 229.        , 227.88000488, 229.53999329,\n",
       "        233.1499939 , 233.44999695, 227.25999451, 224.25999451,\n",
       "        226.46000671, 227.13000488, 231.66999817, 232.03999329,\n",
       "        234.30999756, 233.22999573, 231.80999756, 235.94000244,\n",
       "        233.22999573, 230.33000183, 229.3500061 , 230.13999939,\n",
       "        237.07000732, 235.32000732, 231.57000732, 231.55000305,\n",
       "        231.88000488, 231.1000061 , 232.38999939, 238.05000305,\n",
       "        242.69999695, 246.88000488, 247.19000244, 252.        ,\n",
       "        252.44000244, 254.61999512, 256.82998657, 255.16000366,\n",
       "        257.73001099, 257.6000061 , 257.82000732, 256.83999634,\n",
       "        257.25      , 255.63999939]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_setup('MSFT', 200, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environment_setup(X,y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "        print('Xtrain shape:', X_train.shape)\n",
    "        print('Xtest shape:', X_test.shape)\n",
    "        print('ytrain shape:', y_train.shape)\n",
    "        print('ytest shape:', y_test.shape)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_steps,n_features,optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains model and saves it\n",
    "def train_model(symbol, X_train,y_train,model,epochs):\n",
    "    dirx = r'C:\\Users\\hughx\\Downloads'\n",
    "    os.chdir(dirx)\n",
    "    h5= symbol+'_best_model'+'.h5'\n",
    "    checkpoint = callbacks.ModelCheckpoint(h5, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "    earlystop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=epochs * 1/4, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "    callback = [earlystop,checkpoint] \n",
    "    json = symbol +'_best_model'+'.json'\n",
    "    model_json = model.to_json()\n",
    "    with open(json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=len(X_train)//4, verbose=2,validation_split = 0.3, callbacks = callback)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads the our saved model\n",
    "def load_keras_model(symbol,model,loss,optimizer):\n",
    "    dirx = r'C:\\Users\\hughx\\Downloads'\n",
    "    os.chdir(dirx)\n",
    "    json_file = open(symbol+'_best_model'+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics = None)\n",
    "    model.load_weights(symbol+'_best_model'+'.h5')\n",
    "    return model\n",
    "\n",
    "#uses function above to load most recent model, and evaluates our model\n",
    "def evaluation(symbol, exe_time,X_test, y_test,X_train, y_train ,model,optimizer,loss):\n",
    "    model = load_keras_model(symbol,model,loss,optimizer)\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "    eval_test_loss = round(100-(test_loss*100),1)\n",
    "    eval_train_loss = round(100-(train_loss*100),1)\n",
    "    eval_average_loss = round((eval_test_loss + eval_train_loss)/2,1)\n",
    "    print(\"--- Training Report ---\")\n",
    "#     plot_loss(history)\n",
    "    print('Execution time: ',round(exe_time,2),'s')\n",
    "    print('Testing Accuracy:',eval_test_loss,'%')\n",
    "    print('Training Accuracy:',eval_train_loss,'%')\n",
    "    print('Average Network Accuracy:',eval_average_loss,'%')\n",
    "    return model,eval_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def market_predict(model,minmax,n_features,n_steps,data,test_loss):\n",
    "    \n",
    "    pred_data = data[-1].reshape((len(data[-1]),1, n_steps, n_features))\n",
    "    print(data[-1].shape)\n",
    "    print(data[-1])\n",
    "    print(pred_data.shape)\n",
    "    print(pred_data)\n",
    "    pred = model.predict(pred_data)[0]\n",
    "    print(pred)\n",
    "    appro_loss = list()\n",
    "    for i in range(len(pred)):\n",
    "        pred[i] = pred[i] * (minmax[i][1] - minmax[i][0]) + minmax[i][0]\n",
    "        appro_loss.append(((100-test_loss)/100) * (minmax[i][1] - minmax[i][0]))\n",
    "    return pred,appro_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "First 5 rows of dataframe:                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2018-12-11  181.839996  182.100006  176.009995  176.850006  176.850006   \n",
      "2018-12-12  180.500000  182.949997  179.300003  179.750000  179.750000   \n",
      "2018-12-13  182.389999  183.100006  179.169998  179.899994  179.899994   \n",
      "2018-12-14  177.699997  180.509995  176.479996  177.539993  177.539993   \n",
      "2018-12-17  176.580002  176.779999  167.529999  169.860001  169.860001   \n",
      "\n",
      "             Volume  \n",
      "Date                 \n",
      "2018-12-11  3131700  \n",
      "2018-12-12  2784100  \n",
      "2018-12-13  1797800  \n",
      "2018-12-14  2075000  \n",
      "2018-12-17  4193400  \n",
      "Last row of dataframe:                   Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2021-04-22  215.789993  220.059998  213.339996  214.559998  214.559998   \n",
      "\n",
      "             Volume  \n",
      "Date                 \n",
      "2021-04-22  5458600  \n",
      "original dataset shape: (595, 6)\n",
      "Close shape: (595,)\n",
      "dataset shape: (595, 6)\n",
      "4\n",
      "data shape: (595, 4)\n",
      "X Shape (590, 5, 4)\n",
      "Y shape (590, 4)\n",
      "n_features: 4\n",
      "Reshaped X Shape (590, 1, 5, 4)\n",
      "Y shape (590, 4)\n",
      "true_y shape: 590\n",
      "Xtrain shape: (442, 1, 5, 4)\n",
      "Xtest shape: (148, 1, 5, 4)\n",
      "ytrain shape: (442, 2)\n",
      "ytest shape: (148, 2)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "3/3 - 0s - loss: 0.0971 - val_loss: 0.0723\n",
      "Epoch 2/500\n",
      "3/3 - 0s - loss: 0.0811 - val_loss: 0.0601\n",
      "Epoch 3/500\n",
      "3/3 - 0s - loss: 0.0667 - val_loss: 0.0494\n",
      "Epoch 4/500\n",
      "3/3 - 0s - loss: 0.0545 - val_loss: 0.0394\n",
      "Epoch 5/500\n",
      "3/3 - 0s - loss: 0.0421 - val_loss: 0.0293\n",
      "Epoch 6/500\n",
      "3/3 - 0s - loss: 0.0302 - val_loss: 0.0195\n",
      "Epoch 7/500\n",
      "3/3 - 0s - loss: 0.0191 - val_loss: 0.0110\n",
      "Epoch 8/500\n",
      "3/3 - 0s - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 9/500\n",
      "3/3 - 0s - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 10/500\n",
      "3/3 - 0s - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 11/500\n",
      "3/3 - 0s - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 12/500\n",
      "3/3 - 0s - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 13/500\n",
      "3/3 - 0s - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 14/500\n",
      "3/3 - 0s - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 15/500\n",
      "3/3 - 0s - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 16/500\n",
      "3/3 - 0s - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 17/500\n",
      "3/3 - 0s - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 18/500\n",
      "3/3 - 0s - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 19/500\n",
      "3/3 - 0s - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 20/500\n",
      "3/3 - 0s - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/500\n",
      "3/3 - 0s - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 22/500\n",
      "3/3 - 0s - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 23/500\n",
      "3/3 - 0s - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 24/500\n",
      "3/3 - 0s - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 25/500\n",
      "3/3 - 0s - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 26/500\n",
      "3/3 - 0s - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 27/500\n",
      "3/3 - 0s - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 28/500\n",
      "3/3 - 0s - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 29/500\n",
      "3/3 - 0s - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 30/500\n",
      "3/3 - 0s - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 31/500\n",
      "3/3 - 0s - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 32/500\n",
      "3/3 - 0s - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 33/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 34/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 35/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 36/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 37/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 38/500\n",
      "3/3 - 0s - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 39/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 40/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 41/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 42/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 43/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 44/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 45/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 46/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 47/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 48/500\n",
      "3/3 - 0s - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 49/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 50/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 51/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 52/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 53/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 54/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 55/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 56/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 57/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 58/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 59/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 60/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 61/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 62/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 63/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 64/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 65/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 66/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 67/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 68/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 69/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 70/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 71/500\n",
      "3/3 - 0s - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 72/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9982e-04\n",
      "Epoch 73/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 74/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 75/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9306e-04\n",
      "Epoch 76/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9431e-04\n",
      "Epoch 77/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9875e-04\n",
      "Epoch 78/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8410e-04\n",
      "Epoch 79/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7217e-04\n",
      "Epoch 80/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5741e-04\n",
      "Epoch 81/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8032e-04\n",
      "Epoch 82/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9408e-04\n",
      "Epoch 83/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 84/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7905e-04\n",
      "Epoch 85/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7208e-04\n",
      "Epoch 86/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7039e-04\n",
      "Epoch 87/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7306e-04\n",
      "Epoch 88/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7088e-04\n",
      "Epoch 89/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.6786e-04\n",
      "Epoch 90/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.6103e-04\n",
      "Epoch 91/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8531e-04\n",
      "Epoch 92/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9548e-04\n",
      "Epoch 93/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.9606e-04\n",
      "Epoch 94/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8398e-04\n",
      "Epoch 95/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7891e-04\n",
      "Epoch 96/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8628e-04\n",
      "Epoch 97/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.8641e-04\n",
      "Epoch 98/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.6169e-04\n",
      "Epoch 99/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.4068e-04\n",
      "Epoch 100/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7862e-04\n",
      "Epoch 101/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5154e-04\n",
      "Epoch 102/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5241e-04\n",
      "Epoch 103/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.7867e-04\n",
      "Epoch 104/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5245e-04\n",
      "Epoch 105/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5227e-04\n",
      "Epoch 106/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.5419e-04\n",
      "Epoch 107/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.7897e-04\n",
      "Epoch 108/500\n",
      "3/3 - 0s - loss: 0.0014 - val_loss: 9.6955e-04\n",
      "Epoch 109/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.3866e-04\n",
      "Epoch 110/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.1932e-04\n",
      "Epoch 111/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2327e-04\n",
      "Epoch 112/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.6501e-04\n",
      "Epoch 113/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.8753e-04\n",
      "Epoch 114/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.6398e-04\n",
      "Epoch 115/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.3721e-04\n",
      "Epoch 116/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2655e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.4103e-04\n",
      "Epoch 118/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.5127e-04\n",
      "Epoch 119/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 8.9904e-04\n",
      "Epoch 120/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2043e-04\n",
      "Epoch 121/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.5274e-04\n",
      "Epoch 122/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.6514e-04\n",
      "Epoch 123/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2193e-04\n",
      "Epoch 124/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 8.9715e-04\n",
      "Epoch 125/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.3449e-04\n",
      "Epoch 126/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.3730e-04\n",
      "Epoch 127/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.1145e-04\n",
      "Epoch 128/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.1919e-04\n",
      "Epoch 129/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.1022e-04\n",
      "Epoch 130/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.0312e-04\n",
      "Epoch 131/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2905e-04\n",
      "Epoch 132/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.4193e-04\n",
      "Epoch 133/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 8.9127e-04\n",
      "Epoch 134/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.3047e-04\n",
      "Epoch 135/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.7302e-04\n",
      "Epoch 136/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.2599e-04\n",
      "Epoch 137/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 8.8371e-04\n",
      "Epoch 138/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.0073e-04\n",
      "Epoch 139/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.5246e-04\n",
      "Epoch 140/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 9.4900e-04\n",
      "Epoch 141/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.9043e-04\n",
      "Epoch 142/500\n",
      "3/3 - 0s - loss: 0.0013 - val_loss: 8.7469e-04\n",
      "Epoch 143/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.0192e-04\n",
      "Epoch 144/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.5033e-04\n",
      "Epoch 145/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.9256e-04\n",
      "Epoch 146/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.9213e-04\n",
      "Epoch 147/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.0014e-04\n",
      "Epoch 148/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.1549e-04\n",
      "Epoch 149/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.1380e-04\n",
      "Epoch 150/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.8648e-04\n",
      "Epoch 151/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.0087e-04\n",
      "Epoch 152/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.8084e-04\n",
      "Epoch 153/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.8251e-04\n",
      "Epoch 154/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.7874e-04\n",
      "Epoch 155/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.9606e-04\n",
      "Epoch 156/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.2670e-04\n",
      "Epoch 157/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.7895e-04\n",
      "Epoch 158/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.0052e-04\n",
      "Epoch 159/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.8198e-04\n",
      "Epoch 160/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.7715e-04\n",
      "Epoch 161/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.7274e-04\n",
      "Epoch 162/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.0907e-04\n",
      "Epoch 163/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.6798e-04\n",
      "Epoch 164/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.4489e-04\n",
      "Epoch 165/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.3869e-04\n",
      "Epoch 166/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.5478e-04\n",
      "Epoch 167/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.4130e-04\n",
      "Epoch 168/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 9.3349e-04\n",
      "Epoch 169/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.7981e-04\n",
      "Epoch 170/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.5772e-04\n",
      "Epoch 171/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8935e-04\n",
      "Epoch 172/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9677e-04\n",
      "Epoch 173/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7857e-04\n",
      "Epoch 174/500\n",
      "3/3 - 0s - loss: 0.0012 - val_loss: 8.5041e-04\n",
      "Epoch 175/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0662e-04\n",
      "Epoch 176/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8188e-04\n",
      "Epoch 177/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6023e-04\n",
      "Epoch 178/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6369e-04\n",
      "Epoch 179/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0321e-04\n",
      "Epoch 180/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7022e-04\n",
      "Epoch 181/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.4820e-04\n",
      "Epoch 182/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0920e-04\n",
      "Epoch 183/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7234e-04\n",
      "Epoch 184/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.5446e-04\n",
      "Epoch 185/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6529e-04\n",
      "Epoch 186/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6743e-04\n",
      "Epoch 187/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6135e-04\n",
      "Epoch 188/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.4860e-04\n",
      "Epoch 189/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.4464e-04\n",
      "Epoch 190/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1565e-04\n",
      "Epoch 191/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7632e-04\n",
      "Epoch 192/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6521e-04\n",
      "Epoch 193/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.2143e-04\n",
      "Epoch 194/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8580e-04\n",
      "Epoch 195/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6004e-04\n",
      "Epoch 196/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9164e-04\n",
      "Epoch 197/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1015e-04\n",
      "Epoch 198/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7813e-04\n",
      "Epoch 199/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6301e-04\n",
      "Epoch 200/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1778e-04\n",
      "Epoch 201/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9118e-04\n",
      "Epoch 202/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6529e-04\n",
      "Epoch 203/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.3888e-04\n",
      "Epoch 204/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9234e-04\n",
      "Epoch 205/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7921e-04\n",
      "Epoch 206/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8940e-04\n",
      "Epoch 207/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.3725e-04\n",
      "Epoch 208/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7086e-04\n",
      "Epoch 209/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7812e-04\n",
      "Epoch 210/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1678e-04\n",
      "Epoch 211/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7425e-04\n",
      "Epoch 212/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9006e-04\n",
      "Epoch 213/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.6303e-04\n",
      "Epoch 214/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8868e-04\n",
      "Epoch 215/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.7573e-04\n",
      "Epoch 216/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8272e-04\n",
      "Epoch 217/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1133e-04\n",
      "Epoch 218/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.6949e-04\n",
      "Epoch 219/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8558e-04\n",
      "Epoch 220/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9175e-04\n",
      "Epoch 221/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8980e-04\n",
      "Epoch 222/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.7670e-04\n",
      "Epoch 223/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8926e-04\n",
      "Epoch 224/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.7338e-04\n",
      "Epoch 225/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9314e-04\n",
      "Epoch 226/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.6937e-04\n",
      "Epoch 227/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8878e-04\n",
      "Epoch 228/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.6151e-04\n",
      "Epoch 229/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9216e-04\n",
      "Epoch 230/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8184e-04\n",
      "Epoch 231/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.8427e-04\n",
      "Epoch 232/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8823e-04\n",
      "Epoch 233/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.8459e-04\n",
      "Epoch 234/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0060e-04\n",
      "Epoch 235/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0797e-04\n",
      "Epoch 236/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.7759e-04\n",
      "Epoch 237/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1882e-04\n",
      "Epoch 238/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.1548e-04\n",
      "Epoch 239/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.8881e-04\n",
      "Epoch 240/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.2114e-04\n",
      "Epoch 241/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.8749e-04\n",
      "Epoch 242/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9599e-04\n",
      "Epoch 243/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1259e-04\n",
      "Epoch 244/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1676e-04\n",
      "Epoch 245/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9329e-04\n",
      "Epoch 246/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3663e-04\n",
      "Epoch 247/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.2977e-04\n",
      "Epoch 248/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9441e-04\n",
      "Epoch 249/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 8.9557e-04\n",
      "Epoch 250/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2252e-04\n",
      "Epoch 251/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.8821e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1426e-04\n",
      "Epoch 253/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9994e-04\n",
      "Epoch 254/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0514e-04\n",
      "Epoch 255/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9689e-04\n",
      "Epoch 256/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0246e-04\n",
      "Epoch 257/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1595e-04\n",
      "Epoch 258/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.5444e-04\n",
      "Epoch 259/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1128e-04\n",
      "Epoch 260/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0529e-04\n",
      "Epoch 261/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3249e-04\n",
      "Epoch 262/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9124e-04\n",
      "Epoch 263/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0485e-04\n",
      "Epoch 264/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9783e-04\n",
      "Epoch 265/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2940e-04\n",
      "Epoch 266/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0236e-04\n",
      "Epoch 267/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.5063e-04\n",
      "Epoch 268/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9963e-04\n",
      "Epoch 269/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1417e-04\n",
      "Epoch 270/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3333e-04\n",
      "Epoch 271/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 8.9680e-04\n",
      "Epoch 272/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2178e-04\n",
      "Epoch 273/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3880e-04\n",
      "Epoch 274/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0483e-04\n",
      "Epoch 275/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0646e-04\n",
      "Epoch 276/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.5103e-04\n",
      "Epoch 277/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.0790e-04\n",
      "Epoch 278/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.5923e-04\n",
      "Epoch 279/500\n",
      "3/3 - 0s - loss: 0.0011 - val_loss: 9.4146e-04\n",
      "Epoch 280/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1916e-04\n",
      "Epoch 281/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2151e-04\n",
      "Epoch 282/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3776e-04\n",
      "Epoch 283/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0687e-04\n",
      "Epoch 284/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.0265e-04\n",
      "Epoch 285/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1659e-04\n",
      "Epoch 286/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2017e-04\n",
      "Epoch 287/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1725e-04\n",
      "Epoch 288/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.4131e-04\n",
      "Epoch 289/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1399e-04\n",
      "Epoch 290/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.3125e-04\n",
      "Epoch 291/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.2478e-04\n",
      "Epoch 292/500\n",
      "3/3 - 0s - loss: 0.0010 - val_loss: 9.1972e-04\n",
      "--- Training Report ---\n",
      "Execution time:  10 s\n",
      "Testing Accuracy: 99.9 %\n",
      "Training Accuracy: 99.9 %\n",
      "Average Network Accuracy: 99.9 %\n",
      "(1, 5, 4)\n",
      "[[[0.55873865 0.47940418 0.5368985  0.49401066]\n",
      "  [0.5392915  0.4704742  0.5400017  0.5070038 ]\n",
      "  [0.5556857  0.48008814 0.53753614 0.49272305]\n",
      "  [0.52967256 0.45136037 0.5223602  0.4852706 ]\n",
      "  [0.5146585  0.46735823 0.52503824 0.5112178 ]]]\n",
      "(1, 1, 5, 4)\n",
      "[[[[0.55873865 0.47940418 0.5368985  0.49401066]\n",
      "   [0.5392915  0.4704742  0.5400017  0.5070038 ]\n",
      "   [0.5556857  0.48008814 0.53753614 0.49272305]\n",
      "   [0.52967256 0.45136037 0.5223602  0.4852706 ]\n",
      "   [0.5146585  0.46735823 0.52503824 0.5112178 ]]]]\n",
      "[0.5317471  0.46489453]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([210.48605, 214.00165], dtype=float32),\n",
       " [0.23911001586912706, 0.2631600036620944])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = 'TWTR'\n",
    "myX,myY, myFeatures,  myMinMax, myData, my_nsteps, myclose, myopen, myhigh, mylow = data_setup(stock, 400, 5)\n",
    "\n",
    "myX_train, myX_test, myy_train, myy_test = environment_setup(myX, myY)\n",
    "\n",
    "myModel = initialize_network(5, 4, 'adam')\n",
    "myModel\n",
    "\n",
    "trainedModel = train_model(stock, myX_train,myy_train,myModel,500)\n",
    "\n",
    "models, testloss = evaluation(stock, 10, myX_test, myy_test, myX_train, myy_train ,myModel,'adam','mse')\n",
    "\n",
    "market_predict(models,myMinMax,4,5,myX,testloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
